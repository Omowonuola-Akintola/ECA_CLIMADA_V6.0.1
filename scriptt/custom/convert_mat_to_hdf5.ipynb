{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc1be06-5621-4dc8-abe7-dabd5adb2229",
   "metadata": {},
   "source": [
    "**MATLAB to HDF5 Converter for CLIMADA v6**\n",
    "\n",
    "\n",
    "In CLIMADA v3, it was possible to convert matlab `.mat` files to HDF5. However, this feature was deprecated in newer CLIMADA releases (v6). This notebook documents a replacement approach to perform that same conversion **without** needing to downgrade or maintain older versions of CLIMADA.\n",
    "\n",
    "### Approach\n",
    "\n",
    "1. I studied the HDF5 structure produced by CLIMADA v3  \n",
    "2. Reconstructed the expected HDF5 schema (groups, datasets, dimensions)  \n",
    "3. Wrote a custom script to convert the MATLAB `.mat` hazard data into this HDF5 structure\n",
    "4. Downloaded the file as a hdf5 format into the working folder \n",
    "5. Tested 4 in the example script in the CLIMADA codebase.\n",
    "\n",
    "### How to use\n",
    "Download this notebook and add it into the 'script' folder in the climada codebase. \n",
    "You can either **A**. create a subfolder named 'custom' and add the notebook: {'script/custom/notebook'}  or **B**. add it directly into the 'script' folder: {'script/notebook'}.\n",
    "\n",
    "if you do A, you don't have to change the file path when using the function but make sure to use the correct file path with B\n",
    "\n",
    "### Example File \n",
    "\n",
    "The hdf5 data downloaded into the applications/eca_san_salvador are: 'Salvador_hazard_FL_2015.hdf5 and \n",
    "'Salvador_hazard_FL_2040_extreme_cc.hdf5'.\n",
    "They have been tested and works with all the .ipynb file in the same folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e75e635-ccbb-4068-8e9e-0956a468ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from climada.util.hdf5_handler import get_sparse_csr_mat\n",
    "from climada.hazard.centroids import Centroids\n",
    "from climada.hazard import Hazard\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def convert_mat_to_hdf5(mat_file, hdf5_file):\n",
    "    with h5py.File(mat_file, 'r') as f:\n",
    "    \n",
    "        #define the vars_oblig [units, \"units\",\"centroids\", \"event_id\", \"frequency\", \"intensity\", \"fraction\", } based on the Hazard class in climada\n",
    "\n",
    "        #extract units \n",
    "        unit_value = f['hazard/units'][()]\n",
    "        units = chr(int(unit_value.item()))\n",
    "    \n",
    "        # extract centroids (lat/lon)\n",
    "        lats = f['hazard/lat'][()].flatten()\n",
    "        lons = f['hazard/lon'][()].flatten()\n",
    "        centroids = Centroids(lat=lats, lon=lons)\n",
    "\n",
    "        #extract event_id\n",
    "        event_id = f['hazard/event_ID'][()].flatten() if 'hazard/event_ID' in f else None\n",
    "        if event_id is not None:\n",
    "            if event_id.size == 1:\n",
    "                event_id = int(event_id[0])\n",
    "            else:\n",
    "                event_id = event_id.astype(int)\n",
    "\n",
    "        #extract frequency\n",
    "        frequency = f['hazard/frequency'][()].flatten() if 'hazard/frequency' in f else None\n",
    "\n",
    "        # extract intensity\n",
    "        intensity_dict = {\n",
    "        'data': f['hazard/intensity/data'][()],\n",
    "        'ir': f['hazard/intensity/ir'][()],\n",
    "        'jc': f['hazard/intensity/jc'][()]\n",
    "        }\n",
    "\n",
    "        shape_intensity = (len(event_id), len(lats))  # e.g. (n_centroids, n_events)\n",
    "\n",
    "        intensity_csr = get_sparse_csr_mat(intensity_dict, shape_intensity)\n",
    "\n",
    "        # extract fraction\n",
    "        fraction_dict = {\n",
    "        'data': f['hazard/fraction/data'][()],\n",
    "        'ir': f['hazard/fraction/ir'][()],\n",
    "        'jc': f['hazard/fraction/jc'][()]\n",
    "        }\n",
    "        shape_fraction = (len(event_id), len(lats))  # e.g. (n_centroids, n_events)\n",
    "\n",
    "        fraction_csr = get_sparse_csr_mat(fraction_dict, shape_fraction)\n",
    "\n",
    "        # define var_def {\"date\", \"orig\", \"event_name\",  \"frequency_unit\"} \n",
    "\n",
    "        #extract date\n",
    "        datenum = f['hazard/datenum'][()].flatten()\n",
    "        datenum_int = datenum.astype(int)\n",
    "        date = date = np.insert(datenum_int[:-1], 0, 1)\n",
    "\n",
    "        #extract event_name \n",
    "        name = f['hazard/name']\n",
    "        event_name= []\n",
    "\n",
    "        for i in range(name.shape[0]):\n",
    "            ref_array = name[i]\n",
    "            ref = ref_array[0]\n",
    "            obj = f.file[ref]\n",
    "            ascii_data = obj[()]\n",
    "            s = ''.join(\n",
    "                chr(int(x.item() if isinstance(x, np.ndarray) else x))\n",
    "                for x in ascii_data\n",
    "            )\n",
    "            event_name.append(s)\n",
    "            \n",
    "          # build hazard\n",
    "            haz = Hazard(\n",
    "                haz_type='FL',\n",
    "                centroids=centroids,\n",
    "                event_id=event_id,\n",
    "                event_name=event_name,\n",
    "                intensity=intensity_csr,\n",
    "                fraction=fraction_csr,\n",
    "                frequency=frequency,\n",
    "                units=units,\n",
    "                date=date,\n",
    "            )\n",
    "\n",
    "            # save to HDF5\n",
    "            haz.write_hdf5(hdf5_file)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a551b64-c3d3-4a9b-9473-11d13e136411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-06 17:31:47,301 - climada.hazard.io - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2015.hdf5\n",
      "2025-07-06 17:31:47,304 - climada.hazard.centroids.centr - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2015.hdf5\n",
      "2025-07-06 17:31:47,953 - climada.hazard.io - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2015.hdf5\n",
      "2025-07-06 17:31:47,956 - climada.hazard.centroids.centr - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2015.hdf5\n",
      "2025-07-06 17:31:48,595 - climada.hazard.io - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2015.hdf5\n",
      "2025-07-06 17:31:48,598 - climada.hazard.centroids.centr - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2015.hdf5\n",
      "2025-07-06 17:31:49,266 - climada.hazard.io - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2015.hdf5\n",
      "2025-07-06 17:31:49,269 - climada.hazard.centroids.centr - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2015.hdf5\n",
      "2025-07-06 17:31:49,949 - climada.hazard.io - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2015.hdf5\n",
      "2025-07-06 17:31:49,952 - climada.hazard.centroids.centr - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2015.hdf5\n",
      "2025-07-06 17:31:50,630 - climada.hazard.io - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2015.hdf5\n",
      "2025-07-06 17:31:50,633 - climada.hazard.centroids.centr - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2015.hdf5\n",
      "2025-07-06 17:31:51,383 - climada.hazard.io - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2040_extreme_cc.hdf5\n",
      "2025-07-06 17:31:51,386 - climada.hazard.centroids.centr - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2040_extreme_cc.hdf5\n",
      "2025-07-06 17:31:52,037 - climada.hazard.io - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2040_extreme_cc.hdf5\n",
      "2025-07-06 17:31:52,040 - climada.hazard.centroids.centr - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2040_extreme_cc.hdf5\n",
      "2025-07-06 17:31:52,687 - climada.hazard.io - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2040_extreme_cc.hdf5\n",
      "2025-07-06 17:31:52,691 - climada.hazard.centroids.centr - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2040_extreme_cc.hdf5\n",
      "2025-07-06 17:31:53,343 - climada.hazard.io - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2040_extreme_cc.hdf5\n",
      "2025-07-06 17:31:53,347 - climada.hazard.centroids.centr - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2040_extreme_cc.hdf5\n",
      "2025-07-06 17:31:53,994 - climada.hazard.io - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2040_extreme_cc.hdf5\n",
      "2025-07-06 17:31:53,998 - climada.hazard.centroids.centr - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2040_extreme_cc.hdf5\n",
      "2025-07-06 17:31:54,662 - climada.hazard.io - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2040_extreme_cc.hdf5\n",
      "2025-07-06 17:31:54,666 - climada.hazard.centroids.centr - INFO - Writing ../applications/eca_san_salvador/Salvador_hazard_FL_2040_extreme_cc.hdf5\n"
     ]
    }
   ],
   "source": [
    "convert_mat_to_hdf5(\"../applications/eca_san_salvador/Salvador_hazard_FL_2015.mat\", \"../applications/eca_san_salvador/Salvador_hazard_FL_2015.hdf5\")\n",
    "convert_mat_to_hdf5(\"../applications/eca_san_salvador/Salvador_hazard_FL_2040_extreme_cc.mat\", \"../applications/eca_san_salvador/Salvador_hazard_FL_2040_extreme_cc.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c0746a-cc28-48f9-b77f-77e663e463f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
